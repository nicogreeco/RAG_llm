{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logging\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API ok\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from llama_index.readers.smart_pdf_loader import SmartPDFLoader\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings, StorageContext, load_index_from_storage, VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core import VectorStoreIndex, get_response_synthesizer\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor, PrevNextNodePostprocessor\n",
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.core.schema import MetadataMode\n",
    "from IPython.display import Markdown, display\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# Set the environment variable within the notebook's environment\n",
    "load_dotenv('config.env')\n",
    "llmsherpa_api_url = \"http://localhost:5010/api/parseDocument?renderFormat=all\"\n",
    "PERSIST_DIR = \"./storage\"\n",
    "\n",
    "# Verify it's set\n",
    "if os.getenv('OPENAI_API_KEY'):\n",
    "    print('API ok')\n",
    "\n",
    "\n",
    "# define prompt viewing function\n",
    "def display_prompt_dict(prompts_dict):\n",
    "    for k, p in prompts_dict.items():\n",
    "        text_md = f\"**Prompt Key**: {k}\" f\"**Text:** \"\n",
    "        display(Markdown(text_md))\n",
    "        print(p.get_template())\n",
    "        display(Markdown(\"\"))\n",
    "\n",
    "def display_prompt_from_query_engine(query_engine):\n",
    "    prompts_dict = query_engine.get_prompts()\n",
    "    display_prompt_dict(prompts_dict)\n",
    "\n",
    "def print_response(response):\n",
    "    split_response=response.response.split(sep=' ')\n",
    "    line_length=0\n",
    "    line=[]\n",
    "    for word in split_response:\n",
    "        \n",
    "        if line_length<80:\n",
    "            line_length+= len(word) + 1\n",
    "            line.append(word)\n",
    "            \n",
    "        if line_length>=80:\n",
    "            line_length=0\n",
    "            print(' '.join(line))\n",
    "            line=[]\n",
    "    \n",
    "    if line_length<80:\n",
    "        print(' '.join(line))\n",
    "\n",
    "def move_parsed_doc():\n",
    "    temp_docs = './data_to_add'\n",
    "    docs_dir =  './data'\n",
    "    for document in os.listdir(temp_docs):\n",
    "        shutil.move(os.path.join(temp_docs, document), os.path.join(docs_dir, document))\n",
    "\n",
    "def remove_useless_metadata(documents):\n",
    "    for document in documents:\n",
    "        del document.metadata['file_path']\n",
    "        del document.metadata['file_size']\n",
    "        del document.metadata['creation_date']\n",
    "        del document.metadata['last_modified_date']\n",
    "        del document.metadata['file_type']\n",
    "        del document.metadata['chunk_type']\n",
    "        document.excluded_llm_metadata_keys = []\n",
    "    return documents\n",
    "        \n",
    "def remove_references_and_acknowledgments(documents):\n",
    "    for document in documents[:]:\n",
    "        text = document.text.lower()\n",
    "        if ('reference' in text) or ('acknowledgment' in text) or ('conclusions and perspectives' in text) or ('literature cited' in text) or ('cell science at a glance' in text):\n",
    "            documents.remove(document)\n",
    "    return documents\n",
    "\n",
    "def remove_first_line(documents):\n",
    "    for document in documents:\n",
    "        lines = document.text.splitlines()\n",
    "        modified_text = \"\\n\".join(lines[1:]) if len(lines) > 1 else \"\"\n",
    "        document.text = modified_text\n",
    "    return documents\n",
    "\n",
    "def documents_parsing(documents):\n",
    "    documents = remove_references_and_acknowledgments(documents)\n",
    "    documents = remove_useless_metadata(documents)\n",
    "    documents = remove_first_line(documents)\n",
    "    return documents\n",
    "\n",
    "def add_new_documents_to_index(index, PERSIST_DIR=\"./storage\", llmsherpa_api_url=\"http://localhost:5010/api/parseDocument?renderFormat=all\"):\n",
    "    if len(os.listdir(\"./data_to_add\")) >= 1:\n",
    "        # SmartPDFLoader with `SimpleDirectoryReader`\n",
    "        parser = SmartPDFLoader(llmsherpa_api_url=llmsherpa_api_url)\n",
    "        file_extractor = {\".pdf\": parser}       \n",
    "        documents = SimpleDirectoryReader(\"./data_to_add\",\n",
    "            file_extractor=file_extractor\n",
    "        ).load_data()\n",
    "        documents = documents_parsing(documents)\n",
    "        splitter = SentenceSplitter(chunk_size=1024, chunk_overlap=128)\n",
    "        # Split documents into nodes\n",
    "        nodes = splitter.get_nodes_from_documents(documents)\n",
    "        index.insert_nodes(nodes)\n",
    "        # store it for later\n",
    "        index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
    "\n",
    "        move_parsed_doc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSIST_DIR = \"./storage_smart_pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting Nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicola/miniconda3/envs/llm/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing the nodes\n",
      "Some nodes are missing content, skipping them...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 1758/1758 [00:28<00:00, 61.65it/s]\n"
     ]
    }
   ],
   "source": [
    "## Load or read data\n",
    "\n",
    "# check if storage already exists\n",
    "if not os.path.exists(PERSIST_DIR):\n",
    "    # SmartPDFLoader with `SimpleDirectoryReader`\n",
    "    parser = SmartPDFLoader(llmsherpa_api_url=llmsherpa_api_url)\n",
    "    file_extractor = {\".pdf\": parser}\n",
    "    documents = SimpleDirectoryReader(\n",
    "        \"./data\", file_extractor=file_extractor\n",
    "    ).load_data()\n",
    "    # Remove usless metadata and remove citation sections from documents\n",
    "    documents = documents_parsing(documents)\n",
    "    splitter = SentenceSplitter(chunk_size=1024, chunk_overlap=128)\n",
    "    # Split documents into nodes\n",
    "    print('Splitting Nodes')\n",
    "    nodes = splitter.get_nodes_from_documents(documents)\n",
    "    # Create an index from the nodes\n",
    "    print('Indexing the nodes')\n",
    "    index = VectorStoreIndex(nodes, show_progress=True)\n",
    "    # store it for later\n",
    "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
    "else:\n",
    "    # load the existing index\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "    index = load_index_from_storage(storage_context)\n",
    "    add_new_documents_to_index(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out one file\n",
    "\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core.vector_stores import MetadataFilters, MetadataFilter, FilterOperator\n",
    "\n",
    "# Define metadata filters\n",
    "filters = MetadataFilters(\n",
    "    filters=[MetadataFilter(key=\"file_name\", value='The kinetochore–microtubule interface at a glance.pdf', operator=FilterOperator.EQ)]\n",
    ")\n",
    "\n",
    "# Delete nodes with the specified metadata\n",
    "#index.vector_store.delete_nodes(filters=filters)\n",
    "#index.storage_context.persist(persist_dir=PERSIST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nodes: 1758\n"
     ]
    }
   ],
   "source": [
    "nodes = list(index.docstore.docs.values())\n",
    "total_nodes = len(nodes)\n",
    "print(f\"Total number of nodes: {total_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = OpenAI(temperature=0.6, model=\"o1-preview-2024-09-12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Query Engine for dissertation\n",
    "\n",
    "# configure retriever\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=80,\n",
    ")\n",
    "\n",
    "# configure response synthesizer\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode=\"tree_summarize\",\n",
    ")\n",
    "\n",
    "# assemble query engine with similarity postprocessor\n",
    "query_engine_dissertation = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.85)]\n",
    ")\n",
    "\n",
    "# shakespeare!\n",
    "qa_prompt_tmpl_str = (\n",
    "    \"Context information from multiple scientific papers is below.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the context information and not prior knowledge, \"\n",
    "    \"I want you to write a complete and exhaustive dissertation on this topic(s):\\n\"\n",
    "    \"Topics: {query_str}\\n\"\n",
    "    \"Please use the given topics to compose a complete and exhaustive dissertation, as it is a paragraph of a scientific review on the topic. Drawing on information only from the context provided.\\n\"\n",
    "    \"Be complete and exhaustive and make sure to include all the relevant information from the given context but avoid redundancy in the information.\\n\"\n",
    "    \"Avoid redundancy in the information you write.\\n\"\n",
    "#   \"Give also examples of experimetns made that prove the statments and so where a piece of knowledge cames from.\\n\"\n",
    "    \"Write this as a single paragraph without any subsections or titles and ensure that there is logical flow and coherence between different concepts and pieces of information. Avoid making final summaries or conclusion paragraphs\\n\"\n",
    "    \"I want you to mention also from which file_name and section each piece of information is taken, in brakets as they were citations.\\n\"\n",
    "    \"Use neutral, clear, easy and appropriate language. Write at least 500 words.\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "\n",
    "qa_prompt_tmpl = PromptTemplate(qa_prompt_tmpl_str)\n",
    "\n",
    "query_engine_dissertation.update_prompts(\n",
    "    {\"response_synthesizer:summary_template\": qa_prompt_tmpl}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Query Engine\n",
    "\n",
    "# configure retriever\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=10,\n",
    ")\n",
    "\n",
    "# configure response synthesizer\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode=\"tree_summarize\",\n",
    ")\n",
    "\n",
    "# assemble query engine with similarity postprocessor\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.85)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  The role of intra complex duplications in Ska and Dam1 complex evolution. \n",
      "Intra-complex duplications played a significant role in the evolution of the Ska\n",
      "and Dam1 complexes. Gene duplications contributed to the invention of Dam1-C and\n",
      "Ska-C, indicating that such duplications were a mode of invention shared with other\n",
      "protein complexes (Pereira-Leal et al. 2007). This is evident from the fact that\n",
      "within the Ska-C, all three subunits are homologous to one another, and within Dam1-C,\n",
      "there are two sets of homologous subunits (Duo1-Dad2 and Dad1-Dad4-Ask1). The intra-complex\n",
      "homology reveals that gene duplications were crucial in the formation and evolution\n",
      "of these complexes. This information is derived from the section on page 1297 of\n",
      "the file \"Unique Phylogenetic Distributions of the Ska and Dam1.pdf\".\n"
     ]
    }
   ],
   "source": [
    "# Normal Query\n",
    "query = input()\n",
    "\n",
    "print('Query: ', query)\n",
    "\n",
    "response = query_engine.query(f'{query} I want you to mention also from which file_name and section each piece of information is taken.')\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: \n",
      " Winged Helix domain (or winged Helix turn Helix - wHTH). Its structure, functions and evolutionary history.\n",
      "Answer: \n",
      "The Winged Helix domain (WHD), also known as the winged helix-turn-helix (wHTH)\n",
      "domain, is a specific subtype of the helix-turn-helix (HTH) family of DNA-binding\n",
      "motifs, characterized by a compact α/β structure consisting of three α-helices (H1,\n",
      "H2, H3), three β-strands (S1, S2, S3), and two characteristic loops forming the\n",
      "wings (W1 and W2), arranged in the order H1-S1-H2-H3-S2-W1-S3-W2 (*Winged helix\n",
      "proteins.pdf*). The N-terminal half of the WHD is largely helical, while the C-terminal\n",
      "half comprises the twisted antiparallel β-sheet and the wings, which flank helix\n",
      "H3 like the wings of a butterfly, inspiring the name winged helix motif (*Winged\n",
      "helix proteins.pdf*). The wings, particularly W1, often provide additional interfaces\n",
      "for nucleic acid contact, typically interacting with the minor groove of DNA through\n",
      "charged residues in the hairpin (*The many faces of the helix-turn-helix domain.pdf*).\n",
      "Variations of the WHD exist, with different versions containing two, three, or four\n",
      "β-strands; in the three-stranded version, the loop between helices H1 and H2 assumes\n",
      "an extended configuration and is incorporated as the third strand in the sheet (*The\n",
      "many faces of the helix-turn-helix domain.pdf*). Functionally, the WHD is a widespread\n",
      "nucleic acid-binding structural element found in all kingdoms of life, exhibiting\n",
      "versatility in binding properties and interaction profiles (*From keys to bulldozers_\n",
      "expanding.pdf*). WHD-containing proteins can exploit nearly the full spectrum of\n",
      "nucleic acid structural features for recognition and even covalent modification\n",
      "or noncovalent rearrangement of target molecules, functioning as sequence-recognizing\n",
      "keys in transcription factors and as bulldozer-like strand-separating wedges in\n",
      "helicases, as well as mediators of protein–protein interactions (*From keys to bulldozers_\n",
      "expanding.pdf*). The WHD plays essential roles in transcription systems, being present\n",
      "in components of basal transcription systems, including archaeal transcription factor\n",
      "TFE, and RNA polymerase II transcription factors TFIIEα/β and TFIIFα/β, as well\n",
      "as in structurally related subunits of RNA polymerase I (RPA49) and RNA polymerase\n",
      "III (RPC53, RPC34, and RPC82), suggesting essential functions during transcription\n",
      "initiation (*Structural and functional aspects of winged-helix domains at the core\n",
      "of transcription initiation complexes.pdf*). Evolutionarily, the HTH domain, including\n",
      "the WHD, is one of the most prevalent transcription factor folds, with at least\n",
      "6–11 different HTH domains present in the last universal common ancestor of all\n",
      "life forms, covering much of the structural diversity and functional versatility\n",
      "seen today (*The many faces of the helix-turn-helix domain.pdf*). The WHD has developed\n",
      "several elaborations on the basic three-helical core, such as the tetra-helical\n",
      "bundle and the winged helix configurations, with the latter distinguished by the\n",
      "presence of a C-terminal β-strand hairpin unit that packs against the shallow cleft\n",
      "of the partially open tri-helical core (*The many faces of the helix-turn-helix\n",
      "domain.pdf*). The domain has been recruited to a wide range of functions beyond\n",
      "transcription regulation, including DNA repair and replication, RNA metabolism,\n",
      "and protein–protein interactions in diverse signaling contexts (*The many faces\n",
      "of the helix-turn-helix domain.pdf*). In addition to their DNA-binding roles, WHDs\n",
      "can participate in protein–protein interactions, mediated by exposed hydrophobic\n",
      "patches on their surfaces, as observed in the T4 transcription factor MotA and the\n",
      "p53–MDM2 interaction (*Winged helix proteins.pdf*). The structural versatility of\n",
      "the WHD is further exemplified by its ability to recognize both specific sequences\n",
      "in B-form DNA and distinct double helical conformations, including Z-form DNA (*Winged\n",
      "helix proteins.pdf*). The WHD's evolutionary adaptability is illustrated by its\n",
      "presence in the DNA-binding domains of some of the largest families of prokaryotic\n",
      "transcription factors and several eukaryotic DNA-binding domains, with some versions,\n",
      "such as the La domain and the regulatory factor RFX1, exhibiting unique DNA-binding\n",
      "interactions involving the wings (*The many faces of the helix-turn-helix domain.pdf*).\n",
      "Overall, the WHD represents a remarkable example of structural and functional diversity\n",
      "within a conserved protein fold, playing crucial roles in fundamental biological\n",
      "processes across all domains of life.\n"
     ]
    }
   ],
   "source": [
    "# Dissertation Query\n",
    "query = input()\n",
    "\n",
    "print('Query: \\n', query)\n",
    "\n",
    "response = query_engine_dissertation.query(query)\n",
    "print('Answer: ')\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Winged Helix domain (WHD), also known as the winged helix-turn-helix (wHTH) domain, is a specific subtype of the helix-turn-helix (HTH) family of DNA-binding motifs, characterized by a compact α/β structure consisting of three α-helices (H1, H2, H3), three β-strands (S1, S2, S3), and two characteristic loops forming the wings (W1 and W2), arranged in the order H1-S1-H2-H3-S2-W1-S3-W2 (*Winged helix proteins.pdf*). The N-terminal half of the WHD is largely helical, while the C-terminal half comprises the twisted antiparallel β-sheet and the wings, which flank helix H3 like the wings of a butterfly, inspiring the name winged helix motif (*Winged helix proteins.pdf*). The wings, particularly W1, often provide additional interfaces for nucleic acid contact, typically interacting with the minor groove of DNA through charged residues in the hairpin (*The many faces of the helix-turn-helix domain.pdf*). Variations of the WHD exist, with different versions containing two, three, or four β-strands; in the three-stranded version, the loop between helices H1 and H2 assumes an extended configuration and is incorporated as the third strand in the sheet (*The many faces of the helix-turn-helix domain.pdf*). Functionally, the WHD is a widespread nucleic acid-binding structural element found in all kingdoms of life, exhibiting versatility in binding properties and interaction profiles (*From keys to bulldozers_ expanding.pdf*). WHD-containing proteins can exploit nearly the full spectrum of nucleic acid structural features for recognition and even covalent modification or noncovalent rearrangement of target molecules, functioning as sequence-recognizing keys in transcription factors and as bulldozer-like strand-separating wedges in helicases, as well as mediators of protein–protein interactions (*From keys to bulldozers_ expanding.pdf*). The WHD plays essential roles in transcription systems, being present in components of basal transcription systems, including archaeal transcription factor TFE, and RNA polymerase II transcription factors TFIIEα/β and TFIIFα/β, as well as in structurally related subunits of RNA polymerase I (RPA49) and RNA polymerase III (RPC53, RPC34, and RPC82), suggesting essential functions during transcription initiation (*Structural and functional aspects of winged-helix domains at the core of transcription initiation complexes.pdf*). Evolutionarily, the HTH domain, including the WHD, is one of the most prevalent transcription factor folds, with at least 6–11 different HTH domains present in the last universal common ancestor of all life forms, covering much of the structural diversity and functional versatility seen today (*The many faces of the helix-turn-helix domain.pdf*). The WHD has developed several elaborations on the basic three-helical core, such as the tetra-helical bundle and the winged helix configurations, with the latter distinguished by the presence of a C-terminal β-strand hairpin unit that packs against the shallow cleft of the partially open tri-helical core (*The many faces of the helix-turn-helix domain.pdf*). The domain has been recruited to a wide range of functions beyond transcription regulation, including DNA repair and replication, RNA metabolism, and protein–protein interactions in diverse signaling contexts (*The many faces of the helix-turn-helix domain.pdf*). In addition to their DNA-binding roles, WHDs can participate in protein–protein interactions, mediated by exposed hydrophobic patches on their surfaces, as observed in the T4 transcription factor MotA and the p53–MDM2 interaction (*Winged helix proteins.pdf*). The structural versatility of the WHD is further exemplified by its ability to recognize both specific sequences in B-form DNA and distinct double helical conformations, including Z-form DNA (*Winged helix proteins.pdf*). The WHD's evolutionary adaptability is illustrated by its presence in the DNA-binding domains of some of the largest families of prokaryotic transcription factors and several eukaryotic DNA-binding domains, with some versions, such as the La domain and the regulatory factor RFX1, exhibiting unique DNA-binding interactions involving the wings (*The many faces of the helix-turn-helix domain.pdf*). Overall, the WHD represents a remarkable example of structural and functional diversity within a conserved protein fold, playing crucial roles in fundamental biological processes across all domains of life.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access and print source nodes used for answer\n",
    "print(f'Used {len(response.source_nodes)} nodes to answer:')\n",
    "for node_with_score in response.source_nodes:\n",
    "    print('---------------------------------------------------') \n",
    "    print('---------------------------------------------------')\n",
    "    print(f\"Document ID: {node_with_score.node.id_}\")\n",
    "    print(f\"Metadata: {node_with_score.node.metadata}\")\n",
    "    print(f\"Text: {node_with_score.node.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nodes retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "\n",
    "# Load the index from storage\n",
    "storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "index = load_index_from_storage(storage_context)\n",
    "\n",
    "# Input the query from the user\n",
    "query_str = input(\"Enter your query: \")\n",
    "\n",
    "# Generate the query embedding\n",
    "embed_model = OpenAIEmbedding(model_name=\"text-embedding-3-large\")\n",
    "query_embedding = embed_model.get_text_embedding(query_str)\n",
    "\n",
    "# Create a retriever and perform the query\n",
    "retriever = VectorIndexRetriever(index=index, similarity_top_k=5)\n",
    "query = VectorStoreQuery(query_embedding=query_embedding, similarity_top_k=10)\n",
    "result = retriever.retrieve(query)\n",
    "\n",
    "# Process and print the retrieved nodes\n",
    "for node, similarity, node_id in zip(result.nodes, result.similarities, result.ids):\n",
    "    print(f\"Node ID: {node_id}, Similarity: {similarity}\")\n",
    "    print(f\"Content: {node.get_content()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Direct query the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),  # This is the default and can be omitted\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": input(),\n",
    "        }\n",
    "    ],\n",
    "    model=\"o1-preview-2024-09-12\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
